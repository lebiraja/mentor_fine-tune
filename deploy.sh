#!/bin/bash
# ClarityMentor - Complete Deployment Commands
# Run this script to build and start everything

echo "========================================================================="
echo "üöÄ ClarityMentor Docker Deployment"
echo "========================================================================="
echo ""

# Step 1: Verify model files exist
echo "Step 1: Verifying model files..."
if [ ! -d "models/claritymentor-lora/final" ]; then
    echo "‚ùå ERROR: Model files not found!"
    echo "Expected path: ./models/claritymentor-lora/final/"
    echo ""
    echo "Please ensure your model files are in:"
    echo "  models/claritymentor-lora/final/"
    echo "    ‚îú‚îÄ‚îÄ adapter_model.safetensors"
    echo "    ‚îú‚îÄ‚îÄ tokenizer.json"
    echo "    ‚îú‚îÄ‚îÄ vocab.json"
    echo "    ‚îî‚îÄ‚îÄ ..."
    exit 1
fi
echo "‚úÖ Model files found"
echo ""

# Step 2: Create required directories
echo "Step 2: Creating required directories..."
mkdir -p logs data
echo "‚úÖ Directories created"
echo ""

# Step 3: Check if .env exists
echo "Step 3: Checking environment file..."
if [ ! -f ".env" ]; then
    echo "‚ö†Ô∏è  .env file not found, creating from template..."
    cat > .env << 'EOF'
# ClarityMentor Environment Configuration

# Backend Settings
HOST=0.0.0.0
PORT=2323
DEBUG=False
PYTHONUNBUFFERED=1

# Model Path (inside container)
MODEL_PATH=/app/models/claritymentor-lora/final

# Redis Configuration
REDIS_HOST=cache
REDIS_PORT=6379
REDIS_DB=0

# Voice Configuration
SAMPLE_RATE=16000
CHUNK_SIZE=1024

# Logging
LOG_LEVEL=INFO
LOG_FILE=/app/logs/claritymentor.log
EOF
    echo "‚úÖ .env file created"
else
    echo "‚úÖ .env file exists"
fi
echo ""

# Step 4: Choose GPU or CPU mode
echo "Step 4: Select deployment mode"
echo "========================================================================="
echo "1) GPU mode (Recommended - requires NVIDIA GPU)"
echo "2) CPU only mode (Works everywhere, slower inference)"
echo ""
read -p "Enter choice [1 or 2]: " mode_choice
echo ""

if [ "$mode_choice" = "1" ]; then
    COMPOSE_FILE="docker-compose.yml"
    echo "‚úÖ Using GPU mode"
    echo ""
    echo "Checking GPU availability..."
    if ! command -v nvidia-smi &> /dev/null; then
        echo "‚ö†Ô∏è  WARNING: nvidia-smi not found"
        echo "   GPU may not be available, but continuing anyway..."
        echo "   Backend will fall back to CPU if needed"
    else
        echo "‚úÖ NVIDIA drivers found"
        nvidia-smi --query-gpu=name --format=csv,noheader
    fi
elif [ "$mode_choice" = "2" ]; then
    COMPOSE_FILE="docker-compose.cpu.yml"
    echo "‚úÖ Using CPU-only mode"
else
    echo "‚ùå Invalid choice"
    exit 1
fi
echo ""

# Step 5: Stop any existing containers
echo "Step 5: Stopping any existing containers..."
docker-compose down 2>/dev/null || true
docker-compose -f docker-compose.cpu.yml down 2>/dev/null || true
echo "‚úÖ Cleanup complete"
echo ""

# Step 6: Build images
echo "Step 6: Building Docker images..."
echo "This may take 5-10 minutes on first run..."
echo ""
docker-compose -f $COMPOSE_FILE build
if [ $? -ne 0 ]; then
    echo "‚ùå Build failed!"
    exit 1
fi
echo ""
echo "‚úÖ Images built successfully"
echo ""

# Step 7: Start services
echo "Step 7: Starting services..."
docker-compose -f $COMPOSE_FILE up -d
if [ $? -ne 0 ]; then
    echo "‚ùå Failed to start services!"
    exit 1
fi
echo "‚úÖ Services started"
echo ""

# Step 8: Wait for backend (models loading)
echo "Step 8: Waiting for backend to load models..."
echo "This typically takes 2-3 minutes..."
echo ""

COUNTER=0
MAX_ATTEMPTS=60

while [ $COUNTER -lt $MAX_ATTEMPTS ]; do
    if curl -sf http://localhost:2323/api/health > /dev/null 2>&1; then
        echo ""
        echo "‚úÖ Backend is ready!"
        break
    fi
    printf "."
    sleep 3
    COUNTER=$((COUNTER + 1))
done

if [ $COUNTER -eq $MAX_ATTEMPTS ]; then
    echo ""
    echo "‚ö†Ô∏è  Backend taking longer than expected"
    echo "Check logs: docker-compose logs backend"
else
    echo ""
fi

# Step 9: Wait for frontend
echo ""
echo "Step 9: Checking frontend..."
sleep 5
if curl -sf http://localhost:2000/ > /dev/null 2>&1; then
    echo "‚úÖ Frontend is ready!"
else
    echo "‚ö†Ô∏è  Frontend not responding yet"
    echo "Check logs: docker-compose logs frontend"
fi

# Step 10: Show status
echo ""
echo "========================================================================="
echo "üéâ Deployment Complete!"
echo "========================================================================="
echo ""

# Show container status
docker-compose -f $COMPOSE_FILE ps

echo ""
echo "========================================================================="
echo "üìç Access Points"
echo "========================================================================="
echo ""
echo "üåê Frontend:     http://localhost:2000"
echo "üîå Backend API:  http://localhost:2323"
echo "üìä Health Check: http://localhost:2323/api/health"
echo "üíæ Redis:        localhost:2999"
echo ""

echo "========================================================================="
echo "üìÇ Volume Mounts (Model Files)"
echo "========================================================================="
echo ""
echo "Host ‚Üí Container:"
echo "  ./models/claritymentor-lora/final ‚Üí /app/models/claritymentor-lora/final (read-only)"
echo "  ./config ‚Üí /app/config (read-only)"
echo "  ./data ‚Üí /app/data (read-write)"
echo "  ./logs ‚Üí /app/logs (read-write)"
echo ""

echo "========================================================================="
echo "üõ†Ô∏è  Useful Commands"
echo "========================================================================="
echo ""
echo "View logs (all):      docker-compose -f $COMPOSE_FILE logs -f"
echo "View logs (backend):  docker-compose -f $COMPOSE_FILE logs -f backend"
echo "View logs (frontend): docker-compose -f $COMPOSE_FILE logs -f frontend"
echo ""
echo "Stop services:        docker-compose -f $COMPOSE_FILE down"
echo "Restart backend:      docker-compose -f $COMPOSE_FILE restart backend"
echo "Check status:         docker-compose -f $COMPOSE_FILE ps"
echo ""
echo "Enter backend:        docker-compose -f $COMPOSE_FILE exec backend bash"
echo "Check models:         docker-compose -f $COMPOSE_FILE exec backend ls -la /app/models/claritymentor-lora/final/"
echo ""

echo "========================================================================="
echo "‚úÖ Ready to use!"
echo "========================================================================="
echo ""
echo "Open http://localhost:2000 in your browser and start chatting!"
echo ""
