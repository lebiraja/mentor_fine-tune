FROM nvidia/cuda:12.1.0-devel-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH="${CUDA_HOME}/bin:${PATH}"
ENV LD_LIBRARY_PATH="${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}"

# Set working directory
WORKDIR /app

# Install Python and system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-dev \
    python3-pip \
    build-essential \
    git \
    curl \
    ffmpeg \
    libsndfile1 \
    libsndfile1-dev \
    libportaudio2 \
    portaudio19-dev \
    sox \
    && rm -rf /var/lib/apt/lists/*

# Make python3.10 the default python
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1 \
    && update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

# Upgrade pip and install build dependencies
RUN pip install --no-cache-dir --upgrade pip setuptools wheel

# Install PyTorch with CUDA support (2.5.1 needed for peft 0.18+ / transformers 4.45+)
RUN pip install --no-cache-dir torch==2.5.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121

# Copy our requirements files
COPY requirements_backend.txt requirements_voice.txt ./

# Install backend requirements (FastAPI, etc.)
RUN pip install --no-cache-dir -r requirements_backend.txt

# Install voice requirements (StyleTTS 2, STT, emotion detection, etc.)
RUN pip install --no-cache-dir -r requirements_voice.txt

# Force upgrade packages after styletts2 (which pins old versions)
# peft 0.18+ needed to load the LoRA adapter
# transformers <4.50 to avoid torch 2.6 requirement for torch.load
RUN pip install --no-cache-dir --upgrade "accelerate>=1.2.0" "peft>=0.18.0" "transformers>=4.46.0,<4.50.0"

# Copy backend code
COPY backend/ ./backend/
COPY scripts/ ./scripts/
COPY config/ ./config/

# Create directories for models, data, and logs
RUN mkdir -p /app/models /app/data /app/logs

# Expose the backend port
EXPOSE 2323

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=180s --retries=5 \
    CMD curl -f http://localhost:2323/api/health || exit 1

# Run the FastAPI backend
CMD ["python", "-m", "uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "2323", "--ws-max-size", "10485760"]
